{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Features:\n",
      "       Size  Bedrooms  Bathrooms  YearBuilt  GarageSpaces   HasPool\n",
      "0  0.134649  0.436544  -1.299886   0.346774      1.302937 -0.507801\n",
      "1  0.659080  0.436544  -0.052993  -1.594237     -1.158337  1.969276\n",
      "2 -0.482067 -1.345268  -1.299886   1.462855      1.302937 -0.507801\n",
      "3 -0.988751  0.436544  -0.052993  -1.545712      0.072300 -0.507801\n",
      "4  0.422155  1.327450   1.193900   0.152673      1.302937 -0.507801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Generate synthetic real estate data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# Features\n",
    "size = np.random.randint(1000, 5000, num_samples)  # Size of the house (in square feet)\n",
    "num_bedrooms = np.random.randint(2, 6, num_samples)  # Number of bedrooms\n",
    "num_bathrooms = np.random.randint(1, 4, num_samples)  # Number of bathrooms\n",
    "year_built = np.random.randint(1950, 2020, num_samples)  # Year the house was built\n",
    "garage_spaces = np.random.randint(0, 3, num_samples)  # Number of garage spaces\n",
    "has_pool = np.random.choice([0, 1], size=num_samples, p=[0.8, 0.2])  # Whether the house has a pool\n",
    "\n",
    "# Target variable (price)\n",
    "price = 50000 * size + 30000 * num_bedrooms + 20000 * num_bathrooms + 10000 * (2022 - year_built) + \\\n",
    "        15000 * garage_spaces + 50000 * has_pool + np.random.normal(0, 50000, num_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Size': size,\n",
    "    'Bedrooms': num_bedrooms,\n",
    "    'Bathrooms': num_bathrooms,\n",
    "    'YearBuilt': year_built,\n",
    "    'GarageSpaces': garage_spaces,\n",
    "    'HasPool': has_pool,\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Price'])\n",
    "y = data['Price']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "\n",
    "# Display the first few rows of the preprocessed features\n",
    "print(\"Preprocessed Features:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 9.284923499238645e-06\n",
      "----------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 1.5149822224095716e-05\n",
      "----------------------------------------\n",
      "Model: Ridge Regression\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 2.4336335721415574e-07\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 7.474631241926018e-08\n",
      "----------------------------------------\n",
      "Model: ElasticNet Regression\n",
      "Mean Accuracy: 0.89\n",
      "Standard Deviation: 0.0018306667191352543\n",
      "----------------------------------------\n",
      "Model: Decision Tree\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 4.54122054475033e-05\n",
      "----------------------------------------\n",
      "Model: Extra Trees\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 1.3361107792594644e-06\n",
      "----------------------------------------\n",
      "Model: KNN\n",
      "Mean Accuracy: 0.92\n",
      "Standard Deviation: 0.008744242001102652\n",
      "----------------------------------------\n",
      "Model: Gaussian Process\n",
      "Mean Accuracy: 0.95\n",
      "Standard Deviation: 0.021142087125208226\n",
      "----------------------------------------\n",
      "              Model Name  Training Score  Test Score\n",
      "0          Random Forest        0.999959         NaN\n",
      "1      Gradient Boosting        0.999916         NaN\n",
      "2       Ridge Regression        0.999997         NaN\n",
      "3       Lasso Regression        0.999999         NaN\n",
      "4  ElasticNet Regression        0.887151         NaN\n",
      "5          Decision Tree        0.998900         NaN\n",
      "6            Extra Trees        0.999985         NaN\n",
      "7                    KNN        0.918422         NaN\n",
      "8       Gaussian Process        0.945347         NaN\n"
     ]
    }
   ],
   "source": [
    "def run_ml_pipeline(X_train, X_test, y_train, y_test, models, use_cross_validation=True):\n",
    "    \"\"\"\n",
    "    Run a pipeline of machine learning models on preprocessed data.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Preprocessed training features\n",
    "    - X_test: Preprocessed test features\n",
    "    - y_train: Training target variable\n",
    "    - y_test: Test target variable\n",
    "    - models: List of tuples (model_name, model_instance, model_parameters)\n",
    "    - use_cross_validation: Whether to use cross-validation or model scoring\n",
    "    \"\"\"\n",
    "\n",
    "    score_test = []\n",
    "    score_training = []\n",
    "    model_names = []\n",
    "\n",
    "    for model_name, model, params in models:\n",
    "        # Create a pipeline for each model\n",
    "        pipeline = Pipeline([\n",
    "            ('model', model(**params))\n",
    "        ])\n",
    "\n",
    "        if use_cross_validation:\n",
    "            # Evaluate the model using cross-validation\n",
    "            scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "            mean_score = scores.mean()\n",
    "            std_score = scores.std()\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Mean Accuracy: {mean_score:.2f}\")\n",
    "            print(f\"Standard Deviation: {std_score}\")\n",
    "            print(\"-\" * 40)\n",
    "            score_training.append(mean_score)\n",
    "            score_test.append(np.nan)  # Cross-validation doesn't provide test scores\n",
    "        else:\n",
    "            # Fit the model and compute scores on training and test sets\n",
    "            train_score = pipeline.fit(X_train, y_train).score(X_train, y_train)\n",
    "            test_score = pipeline.score(X_test, y_test)\n",
    "            print(f\"Model: {model_name}\")\n",
    "            print(f\"Training Score: {train_score:.2f}\")\n",
    "            print(f\"Test Score: {test_score:.2f}\")\n",
    "            print(\"-\" * 40)\n",
    "            score_training.append(train_score)\n",
    "            score_test.append(test_score)\n",
    "\n",
    "        model_names.append(model_name)\n",
    "\n",
    "    result = pd.DataFrame({'Model Name': model_names, 'Training Score': score_training, 'Test Score': score_test})\n",
    "    print(result)\n",
    "\n",
    "# Define the list of models to run in the pipeline\n",
    "models = [\n",
    "    ('Random Forest', RandomForestRegressor, {'n_estimators': 100}),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor, {'n_estimators': 100}),\n",
    "    ('Ridge Regression', Ridge, {'alpha': 1.0}),\n",
    "    ('Lasso Regression', Lasso, {'alpha': 1.0}),\n",
    "    ('ElasticNet Regression', ElasticNet, {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
    "    ('Decision Tree', DecisionTreeRegressor, {'max_depth': 5}),\n",
    "    ('Extra Trees', ExtraTreesRegressor, {'n_estimators': 100}),\n",
    "    ('KNN', KNeighborsRegressor, {'n_neighbors': 5}),\n",
    "    ('Gaussian Process', GaussianProcessRegressor, {})\n",
    "]\n",
    "\n",
    "run_ml_pipeline(X_train_scaled, X_test_scaled, y_train, y_test, models, use_cross_validation=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
