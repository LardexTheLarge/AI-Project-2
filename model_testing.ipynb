{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Features:\n",
      "       Size  Bedrooms  Bathrooms  YearBuilt  GarageSpaces   HasPool\n",
      "0  0.643067  0.446879  -1.258811  -0.864921      0.055101 -0.517134\n",
      "1  0.533564  0.446879  -0.021042   0.211643      0.055101 -0.517134\n",
      "2 -0.302164 -1.326450  -1.258811   0.700990     -1.169361 -0.517134\n",
      "3  1.109112  1.333543  -0.021042   1.288206      1.279563 -0.517134\n",
      "4 -1.018751  0.446879  -1.258811  -1.354268      0.055101 -0.517134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "# Generate synthetic real estate data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "# Features\n",
    "size = np.random.randint(1000, 5000, num_samples)  # Size of the house (in square feet)\n",
    "num_bedrooms = np.random.randint(2, 6, num_samples)  # Number of bedrooms\n",
    "num_bathrooms = np.random.randint(1, 4, num_samples)  # Number of bathrooms\n",
    "year_built = np.random.randint(1950, 2020, num_samples)  # Year the house was built\n",
    "garage_spaces = np.random.randint(0, 3, num_samples)  # Number of garage spaces\n",
    "has_pool = np.random.choice([0, 1], size=num_samples, p=[0.8, 0.2])  # Whether the house has a pool\n",
    "\n",
    "# Target variable (price)\n",
    "price = 50000 * size + 30000 * num_bedrooms + 20000 * num_bathrooms + 10000 * (2022 - year_built) + \\\n",
    "        15000 * garage_spaces + 50000 * has_pool + np.random.normal(0, 50000, num_samples)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Size': size,\n",
    "    'Bedrooms': num_bedrooms,\n",
    "    'Bathrooms': num_bathrooms,\n",
    "    'YearBuilt': year_built,\n",
    "    'GarageSpaces': garage_spaces,\n",
    "    'HasPool': has_pool,\n",
    "    'Price': price\n",
    "})\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Price'])\n",
    "y = data['Price']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Display the first few rows of the preprocessed features\n",
    "print(\"Preprocessed Features:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: Ridge Regression\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: Lasso Regression\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: ElasticNet Regression\n",
      "Mean Accuracy: 0.89\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: Decision Tree\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: Extra Trees\n",
      "Mean Accuracy: 1.00\n",
      "Standard Deviation: 0.00\n",
      "----------------------------------------\n",
      "Model: KNN\n",
      "Mean Accuracy: 0.93\n",
      "Standard Deviation: 0.01\n",
      "----------------------------------------\n",
      "Model: Gaussian Process\n",
      "Mean Accuracy: 0.96\n",
      "Standard Deviation: 0.02\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def run_ml_pipeline(X_train, X_test, y_train, y_test, models):\n",
    "    \"\"\"\n",
    "    Run a pipeline of machine learning models on preprocessed data.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Preprocessed features\n",
    "    - y: Target variable\n",
    "    - models: List of tuples (model_name, model_instance, model_parameters)\n",
    "    \"\"\"\n",
    "\n",
    "    score_test = []\n",
    "    score_traning = []\n",
    "    model_nm = []\n",
    "\n",
    "    for model_name, model, params in models:\n",
    "        # Create a pipeline for each model\n",
    "        pipeline = Pipeline([\n",
    "            ('model', model(**params))\n",
    "        ])\n",
    "        model.fit(X_train, y_train_encoded)\n",
    "        train_score = model.score(X_train_scaled,y_train_encoded)\n",
    "        test_score = model.score(X_test_scaled,y_test_encoded)\n",
    "        model_nm.append(model_name)\n",
    "        score_traning.append(train_score)\n",
    "        score_test.append(test_score)\n",
    "    result = pd.DataFrame({'Model Name':model_nm, 'Training Score':score_traning,\n",
    "            'Test_score':score_test})\n",
    "    print(result)\n",
    "        \n",
    "        # # Evaluate the model using cross-validation\n",
    "        # scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "        \n",
    "        # # Print the results\n",
    "        # print(f\"Model: {model_name}\")\n",
    "        # print(f\"Mean Accuracy: {scores.mean():.2f}\")\n",
    "        # print(f\"Standard Deviation: {scores.std():.2f}\")\n",
    "        # print(\"-\" * 40)\n",
    "\n",
    "# Define the list of models to run in the pipeline\n",
    "models = [\n",
    "    ('Random Forest', RandomForestRegressor, {'n_estimators': 100}),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor, {'n_estimators': 100}),\n",
    "    ('Ridge Regression', Ridge, {'alpha': 1.0}),\n",
    "    ('Lasso Regression', Lasso, {'alpha': 1.0}),\n",
    "    ('ElasticNet Regression', ElasticNet, {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
    "    ('Decision Tree', DecisionTreeRegressor, {'max_depth': 5}),\n",
    "    ('Extra Trees', ExtraTreesRegressor, {'n_estimators': 100}),\n",
    "    ('KNN', KNeighborsRegressor, {'n_neighbors': 5}),\n",
    "    ('Gaussian Process', GaussianProcessRegressor, {})\n",
    "]\n",
    "\n",
    "run_ml_pipeline(df, y, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
