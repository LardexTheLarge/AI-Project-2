{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import project_libs as libs\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (4600, 18)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "List of columns\n",
      "['date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'street', 'city', 'statezip', 'country']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Data info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           4600 non-null   object \n",
      " 1   price          4600 non-null   float64\n",
      " 2   bedrooms       4600 non-null   float64\n",
      " 3   bathrooms      4600 non-null   float64\n",
      " 4   sqft_living    4600 non-null   int64  \n",
      " 5   sqft_lot       4600 non-null   int64  \n",
      " 6   floors         4600 non-null   float64\n",
      " 7   waterfront     4600 non-null   int64  \n",
      " 8   view           4600 non-null   int64  \n",
      " 9   condition      4600 non-null   int64  \n",
      " 10  sqft_above     4600 non-null   int64  \n",
      " 11  sqft_basement  4600 non-null   int64  \n",
      " 12  yr_built       4600 non-null   int64  \n",
      " 13  yr_renovated   4600 non-null   int64  \n",
      " 14  street         4600 non-null   object \n",
      " 15  city           4600 non-null   object \n",
      " 16  statezip       4600 non-null   object \n",
      " 17  country        4600 non-null   object \n",
      "dtypes: float64(4), int64(9), object(5)\n",
      "memory usage: 647.0+ KB\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "price            0\n",
      "bedrooms         0\n",
      "bathrooms        0\n",
      "sqft_living      0\n",
      "sqft_lot         0\n",
      "floors           0\n",
      "waterfront       0\n",
      "view             0\n",
      "condition        0\n",
      "sqft_above       0\n",
      "sqft_basement    0\n",
      "yr_built         0\n",
      "yr_renovated     0\n",
      "street           0\n",
      "city             0\n",
      "statezip         0\n",
      "country          0\n",
      "dtype: int64\n",
      "No missing values found. No imputation needed.\n",
      "Data Frame shape (4600, 17)\n",
      "((3680, 16), (920, 16), (3680,), (920,))\n"
     ]
    }
   ],
   "source": [
    "df = libs.read_csv_to_dataframe(\"data/data.csv\")\n",
    "df = df.drop(columns='date', axis=1)\n",
    "df = libs.preprocess_missing_values(df)\n",
    "\n",
    "feature = ['city','statezip','country','street']\n",
    "X_train, X_test, y_train, y_test = libs.Feature_Encoding(df, 'price', feature, encoding_method='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hyperparameter_tuning(model, param_grid, X_train, y_train, scoring):\n",
    "#     grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=1)\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "#     return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "def hyperparameter_tuning(model, param_grid, X_train, y_train, scoring):\n",
    "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, scoring=scoring, n_iter=100, cv=5)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150], # Number of boosting stages (trees)\n",
    "    'learning_rate': [0.01, 0.1, 0.2], # Step size shrinkage used in update to prevent overfitting\n",
    "    'max_depth': [3, 5, 7], # Maximum depth of the individual trees\n",
    "    'min_samples_split': [2, 5, 10],# Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'subsample': [0.8, 1.0],# Subsample ratio of the training instance\n",
    "    'max_features': [10, 'sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    'loss': ['squared_error', 'absolute_error', 'huber', 'quantile']  # Loss function to be optimized\n",
    "}\n",
    "\n",
    "\n",
    "best_model, best_params, best_score = hyperparameter_tuning(model, param_grid, X_train, y_train, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_score)\n",
    "print(best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
